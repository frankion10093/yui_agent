import logging
import numpy as np
import speech_recognition as sr
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

inference_pipeline = pipeline(
        task=Tasks.auto_speech_recognition,
        model='iic/SenseVoiceSmall',
        model_revision="master",
        device="cpu", )

def ai_asr():
    logging.info("ğŸ¤– å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯...")
    #åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨ï¼Œè¿™ä¸ªä¸»è¦è¿˜æ˜¯ç”¨æ¥å®ç°äººå£°çš„è¯†åˆ«çš„ï¼Œå¹¶æ²¡æœ‰ä½¿ç”¨asråŠŸèƒ½
    r = sr.Recognizer()
    r.pause_threshold = 1
    try:
        # å¦‚æœæ£€æµ‹åˆ°äººå£°ï¼Œå¼€å§‹å½•éŸ³ï¼Œé‡‡æ ·ç‡ä¸º16000ï¼Œ60ç§’å†…æ²¡æœ‰äººå£°ä¼šæŠ›å‡ºé”™è¯¯
        with sr.Microphone(sample_rate=16000) as source:
            r.adjust_for_ambient_noise(source, duration=1)
            audio = r.listen(source, timeout=60)
        #ç”±äºfunasrçš„æ¨¡å‹è¾“å…¥è¦æ±‚æ˜¯float32ï¼Œæ‰€ä»¥éœ€è¦å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºfloat32
        audio_data = np.frombuffer(audio.get_raw_data(), dtype=np.int16)
        # è½¬æ¢ä¸ºfloat32,ä¸ºä»€ä¹ˆè¿™é‡Œéœ€è¦/ 32768.0,å®é™…æ˜¯ä¸ºäº†è¾¾åˆ°å½’ä¸€åŒ–ç›®çš„ï¼Œint16å°±æ˜¯2çš„15æ¬¡æ–¹ï¼Œæ‰€ä»¥é™¤ä»¥32768.0å°±æ˜¯å½’ä¸€åŒ–åˆ°[-1,1]
        audio_data = audio_data.astype(np.float32)/ 32768.0
        #è¿™é‡Œè°ƒç”¨funasrçš„æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œç›´æ¥å–[0]['text']ï¼Œå³è¿”å›ç¬¬ä¸€ä¸ªç»“æœçš„æ–‡æœ¬
        # text = model.generate(input=audio_data, sample_rate=16000)[0]["text"]
        text = inference_pipeline(audio_data)[0]['text']
        logging.info(text)
        return text

    except Exception as e:
        logging.error("âŒ Error:è¯­éŸ³è½¬æ–‡å­—å‡ºé”™ï¼å¯èƒ½æ˜¯æ¨¡å‹åŠ è½½å‡ºé”™æˆ–è€…è¾“å…¥è®¾å¤‡é—®é¢˜ï¼")
        print(e)
        return ''

if __name__ == '__main__':
    print(ai_asr())
